{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16 BR_Sn_ibcbr_ibov_Obitos_2015_2020_genetico.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "enYJ0DUZi7Uu",
        "zSV4gtwm3btz",
        "VAZHLUoiBm7a",
        "toz7WX4DBwqg",
        "lDgG-A-dB3Sb",
        "LSUcfijECBWJ",
        "HHnPzBSFCQPw",
        "Pjwhcp5u3hrT",
        "2hrzK_5UfF8i"
      ],
      "machine_shape": "hm",
      "mount_file_id": "10LbICfrbKuUfX4Qrm9YgE5-_iD0KB58V",
      "authorship_tag": "ABX9TyN3CaV6QK2aDNBGzfjyNamW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvb86/PD_LSTM_GA/blob/main/code/16_BR_Sn_ibcbr_ibov_Obitos_2015_2020_genetico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFPYOgDjNr2H"
      },
      "source": [
        "#Algoritimo Genético Para Sintonia de LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aluE5fBf2Jzq"
      },
      "source": [
        "Aplicado a Scenário:\n",
        "* BR padrão 16 épocas\n",
        "* Período 2015-2020\n",
        "\n",
        "##_Entradas_\n",
        "\n",
        "* IBCBR\n",
        "* IBOV\n",
        "* Obitos\n",
        "* Clima \n",
        "* Consumo Resenha EPE:\n",
        "    - Comercial\n",
        "    - Industrial\n",
        "    - Residencial\n",
        "    - Outros\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmBdWoTfth7T"
      },
      "source": [
        "##Declarações Globais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxOPMfT-NRMs",
        "outputId": "72449b0e-a761-4a23-e792-e2e085f625b3"
      },
      "source": [
        "!pip install -U scikit-learn "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSJpsyKqHjH"
      },
      "source": [
        "if 0:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBLzyypzI-xe"
      },
      "source": [
        "import matplotlib.pyplot        as plt\n",
        "import matplotlib.ticker        as ticker\n",
        "import numpy                    as np\n",
        "import pandas                   as pd\n",
        "import seaborn                  as sns\n",
        "import tensorflow               as tf\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random                   as rn\n",
        "import math\n",
        "\n",
        "from datetime                   import datetime, timedelta\n",
        "from sklearn.model_selection    import train_test_split,RepeatedStratifiedKFold \n",
        "from sklearn.preprocessing      import MinMaxScaler\n",
        "from sklearn.preprocessing      import StandardScaler        #Normalização dos dados\n",
        "from sklearn.pipeline           import make_pipeline         #Pipe Line\n",
        "from sklearn.neural_network     import MLPRegressor\n",
        "from sklearn.metrics            import mean_absolute_percentage_error\n",
        "\n",
        "from sklearn.model_selection    import GridSearchCV\n",
        "#from sklearn.svm import SVC\n",
        "from tensorflow                 import keras\n",
        "from tensorflow.keras           import Sequential, layers, callbacks\n",
        "from tensorflow.keras           import backend as K\n",
        "from tensorflow.keras.layers    import Dense, LSTM, Dropout, Bidirectional\n",
        "\n",
        "seed = 170696\n",
        "sns.set()\n",
        "sns.set_theme()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuxq9zajEFsv"
      },
      "source": [
        "#### Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkTKkVw2o5Gu"
      },
      "source": [
        "path  = '/tmp/'\n",
        "patha = path  + 'arcaBR_sn/'\n",
        "pathb = patha + 'bkp/'\n",
        "urla  = patha + 'arca.csv'\n",
        "\n",
        "prefGo    = 'https://docs.google.com/uc?export=download&id='\n",
        "\n",
        "urld        = prefGo + '1oN489-qxjCNJwUlLrO6sAUSozGzTaG7C'\n",
        "urlibc      = prefGo + '1QrbgeR7TyHbcNx3l-ke2RD33kn0p0BgY'\n",
        "urlTabnet   = prefGo + '1z1vn0D9Efnl-wRO_tYDZafZhLGRrPwc0'\n",
        "urlEPE      = prefGo + '1Qb8aIVyaUpvSn_l6-tbDRtIkUv5RANvN'\n",
        "urlclima    = prefGo + '1m11IcEh6gNRZC_uuAozBvQp1Ji4c0YvQ'\n",
        "urlibov     = prefGo + '1S2SQ98qk3V52LnYde04QR2k-X8VhZ_n6'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbyVzPNDD4_B"
      },
      "source": [
        "### Randon Freeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg7TzVR-8udi"
      },
      "source": [
        "def imports():\n",
        "    import matplotlib.pyplot        as plt\n",
        "    import matplotlib.ticker        as ticker\n",
        "    import numpy                    as np\n",
        "    import pandas                   as pd\n",
        "    import seaborn                  as sns\n",
        "    import tensorflow               as tf\n",
        "    import os\n",
        "    import glob\n",
        "    import shutil\n",
        "    import random                   as rn\n",
        "    import math\n",
        "\n",
        "    from datetime                   import datetime, timedelta\n",
        "    from sklearn.model_selection    import train_test_split,RepeatedStratifiedKFold \n",
        "    from sklearn.preprocessing      import MinMaxScaler\n",
        "    from sklearn.preprocessing      import StandardScaler        #Normalização dos dados\n",
        "    from sklearn.pipeline           import make_pipeline         #Pipe Line\n",
        "    from sklearn.neural_network     import MLPRegressor\n",
        "    from sklearn.metrics            import mean_absolute_percentage_error\n",
        "\n",
        "    from sklearn.model_selection    import GridSearchCV\n",
        "    #from sklearn.svm import SVC\n",
        "    from tensorflow                 import keras\n",
        "    from tensorflow.keras           import Sequential, layers, callbacks\n",
        "    from tensorflow.keras           import backend as K\n",
        "    from tensorflow.keras.layers    import Dense, LSTM, Dropout, Bidirectional\n",
        "\n",
        "    seed = 170696\n",
        "    sns.set()\n",
        "    sns.set_theme()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ1eWA0nEdqW"
      },
      "source": [
        "# Utilizando o essa foi a unica maneira encontrada para congelar o randon e \n",
        "# garantir a reprodutibilidade do modelo \n",
        "\n",
        "def reset_seed(seed,keras=False, verbose = False):\n",
        "    imports()\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    np.random.seed(seed)\n",
        "    rn.seed(seed)\n",
        "\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "    from keras import backend as K\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    K.set_session(sess)\n",
        "\n",
        "def set_seed_rand(verbose = False):\n",
        "    \n",
        "    from datetime import datetime\n",
        "\n",
        "    dt_seg_now = datetime.now().strftime(\"%S\")\n",
        "    #print(\"\\t\\tSEED =\", dt_seg_now)\t\n",
        "    nseed = int(dt_seg_now)\n",
        "    os.environ['PYTHONHASHSEED'] = str(nseed)\n",
        "    np.random.seed(nseed)\n",
        "    rn.seed(nseed)\n",
        "    if verbose: print(\"\\t\\tSEED =\", dt_seg_now)\t\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whIuBgDEttjg"
      },
      "source": [
        "## Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHFCzEZJcki7"
      },
      "source": [
        "anoIni = 2015\n",
        "anoFim = 2020"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "pN8U9O0wzihn",
        "outputId": "303ff5f2-75cb-4ce1-c84a-043e48a5d411"
      },
      "source": [
        "ibov = pd.read_csv(urlibov, sep=';', decimal=',', thousands='.', skiprows=1, skip_blank_lines=True, header=0, encoding='Latin-1')\n",
        "\n",
        "ibov['mm'] = '0' + ibov['Mês'].astype(str)\n",
        "ibov['Ano Mês'] = ibov.Ano.astype(str) + '-' +ibov.mm.str[-2:]\n",
        "ibov = ibov[(ibov.Ano.astype(int) >= anoIni )*(ibov.Ano.astype(int) <= anoFim)]\n",
        "ibov.rename(columns={'Valor':'ibov'}, inplace = True)\n",
        "ibov.head(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
            "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mês</th>\n",
              "      <th>Ano</th>\n",
              "      <th>ibov</th>\n",
              "      <th>mm</th>\n",
              "      <th>Ano Mês</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>46907.68</td>\n",
              "      <td>01</td>\n",
              "      <td>2015-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2</td>\n",
              "      <td>2015</td>\n",
              "      <td>51583.09</td>\n",
              "      <td>02</td>\n",
              "      <td>2015-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Mês   Ano      ibov  mm  Ano Mês\n",
              "36    1  2015  46907.68  01  2015-01\n",
              "37    2  2015  51583.09  02  2015-02"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWWkGeME5BHz",
        "outputId": "850750b4-c694-4817-c125-801f32a01c6d"
      },
      "source": [
        "ibov.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 72 entries, 36 to 107\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   Mês      72 non-null     int64  \n",
            " 1   Ano      72 non-null     int64  \n",
            " 2   ibov     72 non-null     float64\n",
            " 3   mm       72 non-null     object \n",
            " 4   Ano Mês  72 non-null     object \n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 3.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHT3FNu9JHhe",
        "outputId": "87fc31bc-52c5-4080-aa96-a55769bcc318"
      },
      "source": [
        "ibcbr = pd.read_csv(urlibc, sep =';' ,decimal=',',parse_dates=True, dayfirst=True,encoding='UTF8', index_col='data' )\n",
        "ibcbr = ibcbr[(ibcbr.index.year >= anoIni )*(ibcbr.index.year <= anoFim)]\n",
        "ibcbr.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9RHS8UnKBqt"
      },
      "source": [
        "ibcbr['Ano Mês']= ibcbr.index.year.astype(str) +'-'+ ('0' + ibcbr.index.month.astype(str)).str[-2:]\n",
        "ibcbr = ibcbr.rename(columns={'valor':'ibcbr'})\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w8DV64flnOi",
        "outputId": "504dd4dc-efb9-445a-a516-b2cabbe58026"
      },
      "source": [
        "tabnet = pd.read_csv(urlTabnet, sep =';', decimal=',', skiprows=3, skipfooter=6, encoding='latin_1')\n",
        "tabnet['Ano/mês processamento'] = tabnet['Ano/mês processamento'].str.replace('..','',regex=False)\n",
        "tabnet = tabnet[tabnet['Ano/mês processamento'].str.len() >= 6]\n",
        "tabnet['Ano'] = tabnet['Ano/mês processamento'].str[-4:]\n",
        "tabnet['Mês'] = tabnet['Ano/mês processamento'].str[:-5]\n",
        "tabnet['Mês'] = tabnet['Mês'].str.strip()\n",
        "mapmes = {'Janeiro':'01', 'Fevereiro':'02', 'Março':'03', 'Abril':'04', 'Maio':'05', 'Junho':'06',\n",
        " 'Julho':'07', 'Agosto':'08', 'Setembro':'09', 'Outubro':'10', 'Novembro':'11', 'Dezembro':'12'}\n",
        "tabnet['mm'] = tabnet['Mês'].map(mapmes)\n",
        "tabnet.drop(columns = 'Ano/mês processamento')\n",
        "tabnet['Ano Mês'] = tabnet.Ano +'-'+ tabnet.mm \n",
        "tabnet = tabnet.rename(columns = {'Total': 'BR'})\n",
        "obtosBR = tabnet[tabnet.Ano.astype(int) <= anoFim][['Ano Mês', 'BR']]\n",
        "obtosBR = obtosBR.rename(columns = {'BR':'Obitos'})\n",
        "obtosBR.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cXKwJiABz0ma",
        "outputId": "a592c032-94d5-49ea-d769-e942346c35d5"
      },
      "source": [
        "pd.read_csv(urlEPE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ano</th>\n",
              "      <th>Mes</th>\n",
              "      <th>Total</th>\n",
              "      <th>Norte</th>\n",
              "      <th>Nordeste</th>\n",
              "      <th>Sudeste</th>\n",
              "      <th>Sul</th>\n",
              "      <th>CentoOeste</th>\n",
              "      <th>Ano Mês</th>\n",
              "      <th>Setor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>13597745.91</td>\n",
              "      <td>830281.77</td>\n",
              "      <td>2758984.88</td>\n",
              "      <td>6571311.64</td>\n",
              "      <td>2260371.61</td>\n",
              "      <td>1176796.01</td>\n",
              "      <td>2021-01</td>\n",
              "      <td>Residencial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021</td>\n",
              "      <td>2</td>\n",
              "      <td>12816225.52</td>\n",
              "      <td>803678.00</td>\n",
              "      <td>2619758.51</td>\n",
              "      <td>6192199.70</td>\n",
              "      <td>2107756.15</td>\n",
              "      <td>1092833.16</td>\n",
              "      <td>2021-02</td>\n",
              "      <td>Residencial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>13204377.21</td>\n",
              "      <td>820022.59</td>\n",
              "      <td>2727749.08</td>\n",
              "      <td>6321507.66</td>\n",
              "      <td>2190795.20</td>\n",
              "      <td>1144302.68</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>Residencial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021</td>\n",
              "      <td>4</td>\n",
              "      <td>13295462.41</td>\n",
              "      <td>864941.75</td>\n",
              "      <td>2774864.34</td>\n",
              "      <td>6349461.85</td>\n",
              "      <td>2109543.78</td>\n",
              "      <td>1196650.69</td>\n",
              "      <td>2021-04</td>\n",
              "      <td>Residencial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021</td>\n",
              "      <td>5</td>\n",
              "      <td>11916732.03</td>\n",
              "      <td>859232.55</td>\n",
              "      <td>2536646.39</td>\n",
              "      <td>5591479.32</td>\n",
              "      <td>1867454.95</td>\n",
              "      <td>1061918.82</td>\n",
              "      <td>2021-05</td>\n",
              "      <td>Residencial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>2004</td>\n",
              "      <td>8</td>\n",
              "      <td>3892772.35</td>\n",
              "      <td>212999.10</td>\n",
              "      <td>726332.07</td>\n",
              "      <td>1833404.77</td>\n",
              "      <td>714015.51</td>\n",
              "      <td>406020.90</td>\n",
              "      <td>2004-08</td>\n",
              "      <td>Outros</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>2004</td>\n",
              "      <td>9</td>\n",
              "      <td>4045925.14</td>\n",
              "      <td>214694.08</td>\n",
              "      <td>766592.08</td>\n",
              "      <td>1890523.79</td>\n",
              "      <td>738705.75</td>\n",
              "      <td>435409.44</td>\n",
              "      <td>2004-09</td>\n",
              "      <td>Outros</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>2004</td>\n",
              "      <td>10</td>\n",
              "      <td>4226884.42</td>\n",
              "      <td>218705.12</td>\n",
              "      <td>798723.62</td>\n",
              "      <td>2053894.16</td>\n",
              "      <td>734053.68</td>\n",
              "      <td>421507.84</td>\n",
              "      <td>2004-10</td>\n",
              "      <td>Outros</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>2004</td>\n",
              "      <td>11</td>\n",
              "      <td>4054988.32</td>\n",
              "      <td>214175.36</td>\n",
              "      <td>813985.52</td>\n",
              "      <td>1908302.43</td>\n",
              "      <td>752820.39</td>\n",
              "      <td>365704.62</td>\n",
              "      <td>2004-11</td>\n",
              "      <td>Outros</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>4126714.61</td>\n",
              "      <td>223895.24</td>\n",
              "      <td>800357.98</td>\n",
              "      <td>1900467.61</td>\n",
              "      <td>837837.10</td>\n",
              "      <td>364156.68</td>\n",
              "      <td>2004-12</td>\n",
              "      <td>Outros</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>840 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Ano  Mes        Total  ...  CentoOeste  Ano Mês        Setor\n",
              "0    2021    1  13597745.91  ...  1176796.01  2021-01  Residencial\n",
              "1    2021    2  12816225.52  ...  1092833.16  2021-02  Residencial\n",
              "2    2021    3  13204377.21  ...  1144302.68  2021-03  Residencial\n",
              "3    2021    4  13295462.41  ...  1196650.69  2021-04  Residencial\n",
              "4    2021    5  11916732.03  ...  1061918.82  2021-05  Residencial\n",
              "..    ...  ...          ...  ...         ...      ...          ...\n",
              "835  2004    8   3892772.35  ...   406020.90  2004-08       Outros\n",
              "836  2004    9   4045925.14  ...   435409.44  2004-09       Outros\n",
              "837  2004   10   4226884.42  ...   421507.84  2004-10       Outros\n",
              "838  2004   11   4054988.32  ...   365704.62  2004-11       Outros\n",
              "839  2004   12   4126714.61  ...   364156.68  2004-12       Outros\n",
              "\n",
              "[840 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLl4itjaYpQx"
      },
      "source": [
        "dfEPE = pd.read_csv(urlEPE)\n",
        "dfEPE = dfEPE[(dfEPE.Ano >= anoIni) & (dfEPE.Ano <= anoFim)]\n",
        "dfEPE = dfEPE.pivot(index = ['Ano Mês','Mes'], columns='Setor',values = 'Total')\n",
        "dfEPE['Consumo'] = dfEPE.Comercial + dfEPE.Residencial + dfEPE.Comercial + dfEPE.Outros"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6RbWoun2GBn"
      },
      "source": [
        "clima = pd.read_csv(urlclima, index_col=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvqOnfs15MK"
      },
      "source": [
        "df = dfEPE.reset_index()\n",
        "df = pd.merge(df,ibcbr[['Ano Mês','ibcbr']],left_on='Ano Mês',right_on='Ano Mês')\n",
        "df = pd.merge(df,ibov[['Ano Mês','ibov']],left_on='Ano Mês',right_on='Ano Mês')\n",
        "df = pd.merge(df,obtosBR[['Ano Mês','Obitos']],left_on='Ano Mês',right_on='Ano Mês')\n",
        "df = pd.merge(df,clima.reset_index()[['Ano Mês','Dias com Precipitação','Precipitação', 'Pressão', 'Temperatura', 'Vento Máx', 'Vento Méd' ]],              left_on='Ano Mês',right_on='Ano Mês')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "a7DNt_QkxW7-",
        "outputId": "9c0819ab-3176-4a4d-c69b-9ac42bd1c4ef"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ano Mês</th>\n",
              "      <th>Mes</th>\n",
              "      <th>Comercial</th>\n",
              "      <th>Industrial</th>\n",
              "      <th>Outros</th>\n",
              "      <th>Residencial</th>\n",
              "      <th>Consumo</th>\n",
              "      <th>ibcbr</th>\n",
              "      <th>ibov</th>\n",
              "      <th>Obitos</th>\n",
              "      <th>Dias com Precipitação</th>\n",
              "      <th>Precipitação</th>\n",
              "      <th>Pressão</th>\n",
              "      <th>Temperatura</th>\n",
              "      <th>Vento Máx</th>\n",
              "      <th>Vento Méd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01</td>\n",
              "      <td>1</td>\n",
              "      <td>8076142.86</td>\n",
              "      <td>13756016.06</td>\n",
              "      <td>6367506.54</td>\n",
              "      <td>12558302.07</td>\n",
              "      <td>35078094.33</td>\n",
              "      <td>138.99</td>\n",
              "      <td>46907.68</td>\n",
              "      <td>38552</td>\n",
              "      <td>15.925879</td>\n",
              "      <td>157.847785</td>\n",
              "      <td>913.494719</td>\n",
              "      <td>24.172344</td>\n",
              "      <td>7.075639</td>\n",
              "      <td>2.038770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02</td>\n",
              "      <td>2</td>\n",
              "      <td>8089865.00</td>\n",
              "      <td>14444648.60</td>\n",
              "      <td>6404491.76</td>\n",
              "      <td>11780261.00</td>\n",
              "      <td>34364482.76</td>\n",
              "      <td>136.71</td>\n",
              "      <td>51583.09</td>\n",
              "      <td>37172</td>\n",
              "      <td>20.168051</td>\n",
              "      <td>189.888113</td>\n",
              "      <td>912.905095</td>\n",
              "      <td>23.491022</td>\n",
              "      <td>6.767799</td>\n",
              "      <td>1.992923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ano Mês  Mes   Comercial  ...  Temperatura  Vento Máx  Vento Méd\n",
              "0  2015-01    1  8076142.86  ...    24.172344   7.075639   2.038770\n",
              "1  2015-02    2  8089865.00  ...    23.491022   6.767799   1.992923\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXGZBmmzRAsY",
        "outputId": "04c62ad2-615f-4be6-fbed-3e39cdb85aad"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Ano Mês', 'Mes', 'Comercial', 'Industrial', 'Outros', 'Residencial',\n",
              "       'Consumo', 'ibcbr', 'ibov', 'Obitos', 'Dias com Precipitação',\n",
              "       'Precipitação', 'Pressão', 'Temperatura', 'Vento Máx', 'Vento Méd'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFv_OLy4OPyv",
        "outputId": "9d30d6b4-7b28-41fb-f878-d8fe22b2073d"
      },
      "source": [
        "\n",
        "df['mes_sin'] = np.sin(df['Mes']*2*np.pi/12)\n",
        "df['mes_cos'] = np.cos(df['Mes']*2*np.pi/12)\n",
        "d = df.drop(columns=['Ano Mês', 'Mes']).reset_index()\n",
        "Ycolumns = ['Consumo', 'Comercial', 'Industrial', 'Residencial', 'Outros']\n",
        "Xcolumns = [*{*d.columns.to_list()}-{*Ycolumns,'index','level_0'}]\n",
        "\n",
        "print('X\\n',len(Xcolumns),'\\n', Xcolumns)\n",
        "print('Y\\n',len(Ycolumns),'\\n', Ycolumns)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            " 11 \n",
            " ['mes_cos', 'Vento Máx', 'Vento Méd', 'ibcbr', 'Precipitação', 'Dias com Precipitação', 'Obitos', 'ibov', 'Temperatura', 'Pressão', 'mes_sin']\n",
            "Y\n",
            " 5 \n",
            " ['Consumo', 'Comercial', 'Industrial', 'Residencial', 'Outros']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zQj7AyEuGAX"
      },
      "source": [
        "## Funções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYJ0DUZi7Uu"
      },
      "source": [
        "#### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7-WKf2s8MEz",
        "outputId": "4dc1861f-5177-4c03-af75-ad056e1d0015"
      },
      "source": [
        "df.shape[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMgKtp0l56W"
      },
      "source": [
        "def TrainTestData(col_i):\n",
        "    lin = df.shape[0]\n",
        "    lin_train = lin - 12\n",
        "    X = d[Xcolumns]\n",
        "    y = d[Ycolumns]\n",
        "    y = y.iloc[:,col_i]\n",
        "    # Different scaler for input and output\n",
        "    scaler_x = MinMaxScaler(feature_range = (0,1))\n",
        "    scaler_y = MinMaxScaler(feature_range = (0,1))\n",
        "    #print(2)\n",
        "    # Fit the scaler using available training data\n",
        "    input_scaler = scaler_x.fit(X)\n",
        "    X_norm = input_scaler.transform(X)\n",
        "    #print('y_shape= ',y.shape)\n",
        "    #print('y_shape= ',len(y.shape))\n",
        "    if len(y.shape) == 1:\n",
        "       # print('..reshape')\n",
        "        output_scaler = scaler_y.fit(y.to_numpy().reshape(-1,1))\n",
        "        y_norm = output_scaler.transform(y.to_numpy().reshape(-1,1))\n",
        "    else:\n",
        "        output_scaler = scaler_y.fit(y)\n",
        "        y_norm = output_scaler.transform(y)\n",
        "        \n",
        "    X_train = X_norm[:lin_train]\n",
        "    y_train = y_norm[:lin_train]\n",
        "\n",
        "    X_test = X_norm[lin_train:]\n",
        "    y_test = y_norm[lin_train:]\n",
        "\n",
        "    y_real = y[lin_train:]\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "    #print(\"Dimensões X: \",'X_train',X_train.shape,'X_test', X_test.shape)\n",
        "    #print(\"Dimensões Y: \",'Y_train',y_train.shape,'Y_test', y_test.shape)\n",
        "\n",
        "    shape_in = X_train.shape[2]\n",
        "    shape_out = y_train.shape[1]\n",
        "\n",
        "    return shape_in, shape_out, X_train, y_train, X_test, y_test, y_real, input_scaler, output_scaler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OheHud4aOarW"
      },
      "source": [
        "def TrainTestData_old(verbose=False):\n",
        "    lin = df.shape[0]\n",
        "    lin_train = lin - 12\n",
        "    X = d[Xcolumns]\n",
        "    y = d[Ycolumns]\n",
        "    # Different scaler for input and output\n",
        "    scaler_x = MinMaxScaler(feature_range = (0,1))\n",
        "    scaler_y = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "    # Fit the scaler using available training data\n",
        "    input_scaler = scaler_x.fit(X)\n",
        "    #output_scaler = scaler_y.fit(y.to_numpy().reshape(-1,1))\n",
        "    output_scaler = scaler_y.fit(y)\n",
        "\n",
        "    # Apply the scaler to training data\n",
        "    X_norm = input_scaler.transform(X)\n",
        "    #y_norm = output_scaler.transform(y.to_numpy().reshape(-1,1))\n",
        "    y_norm = output_scaler.transform(y)\n",
        "\n",
        "    X_train = X_norm[:lin_train]\n",
        "    y_train = y_norm[:lin_train]\n",
        "\n",
        "    X_test = X_norm[lin_train:]\n",
        "    y_test = y_norm[lin_train:]\n",
        "\n",
        "    y_real = y[lin_train:]\n",
        "\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "    if verbose:\n",
        "        print(\"Dimensões X: \",'X_train',X_train.shape,'X_test', X_test.shape)\n",
        "        print(\"Dimensões Y: \",'Y_train',y_train.shape,'Y_test', y_test.shape)\n",
        "\n",
        "    shape_in = X_train.shape[2]\n",
        "    shape_out = y_train.shape[1]\n",
        "\n",
        "    return X,y,input_scaler,output_scaler,X_train,y_train,X_test,y_test,y_real,shape_in, shape_out"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSV4gtwm3btz"
      },
      "source": [
        "###Genéticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAZHLUoiBm7a"
      },
      "source": [
        "#### Inicia Populacão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4gEOCbodLAz"
      },
      "source": [
        "def inicializa_populacao(pop_tamanho, n_genes, limites):\n",
        "    \"\"\"\n",
        "    Inicializa a população de acordo com o tamanho da população\n",
        "    e número de genes.\n",
        "\n",
        "    param pop_tamanho:     Número de individuos na população\n",
        "    param n_genes:         Número de genes (Variáveis) no problema\n",
        "    param limites:         Tupla contendo o número mínimo e máximo permitido  \n",
        "    return:                Um array numpy com a população iniciada \n",
        "                           randomicamente\n",
        "    \"\"\"\n",
        "\n",
        "    pop0 = np.random.randint(\n",
        "      limites[0], limites[1], size=(pop_tamanho, n_genes)\n",
        "    )\n",
        "    pop=[]\n",
        "    for e, i in enumerate(pop0):\n",
        "        if np.sum(i) == 0:\n",
        "            n = np.random.randint(limites[0]+1, limites[1], size=(1, n_genes))\n",
        "            #print(e,i,n)\n",
        "            pop.append(n)\n",
        "        else:    \n",
        "            pop.append(i)\n",
        "    return pop"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toz7WX4DBwqg"
      },
      "source": [
        "####Função de aptidão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1M0mjWdt9z6"
      },
      "source": [
        "def rede_desc(bl_list, unit_list, drop_list):\n",
        "    '''\n",
        "    Retorna descrição gráfica da Rede\n",
        "\n",
        "    '''\n",
        "    dic_bl = {0: 'LSTM', 1:'BILSTM'}\n",
        "    desc = '->'\n",
        "    for e,i in enumerate(unit_list):\n",
        "        if i >0:\n",
        "            if e < 2:\n",
        "                desc+=(f'{dic_bl[bl_list[e]]}')   \n",
        "            else:\n",
        "                desc+=('MLP')\n",
        "            desc+=(f'({unit_list[e]})->')\n",
        "            if e < 5:\n",
        "                desc+=(f'd({drop_list[e]})->')\n",
        "    return desc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDEjjqkuPPN"
      },
      "source": [
        "def decode_gen(chave, verbose = False):\n",
        "    '''\n",
        "    Recebe chave genética e retorna estrutura da rede \n",
        "    considerando arquitetura predefinida \n",
        "\n",
        "            Tipo---\\ Dropout -----------------\\ Neurônios-------------------\\ \n",
        "            B|L  B|L  D12  D23  D34  D45  D56  NL1  NL2  NL3  NL4  NL5  NL6              \n",
        "    chave =[ p01, p02, p03, p04, p05, p06, p07, p07, p08, p09, p10, p11, p12]\n",
        "            2|1  2|1  2|1  2|1  2|1\n",
        "\n",
        "    Tipo      -> se par BILSTM se não LSTM\n",
        "    Dropout   -> If 0 = 0 \n",
        "                Else\n",
        "                    Se par 0.2 senão 0.1 \n",
        "    Neurônios -> If 0 desetiva layer e dropout seguinte \n",
        "                Else numero de neurônios da camada                \n",
        "    '''\n",
        "\n",
        "    bl_list = []\n",
        "    drop_list = []\n",
        "    unit_list = []\n",
        "    Lini = 0\n",
        "    Lcount = 0\n",
        "\n",
        "    for i in range(7,13):\n",
        "        if chave[i] >0:\n",
        "            ini = i-6\n",
        "            break\n",
        "    for i in range(7,13):\n",
        "        if chave[i] >0:\n",
        "            Lcount +=1\n",
        "    if verbose: print(f'\\tN Layers = {Lcount}')\n",
        "    else: print('.',sep='',end='')\n",
        "\n",
        "    for i in range(2):\n",
        "        if chave[i] % 2 == 0:\n",
        "            bl_list.append(1)\n",
        "        else:\n",
        "            bl_list.append(0)\n",
        "\n",
        "    for i in range(2,7):\n",
        "        if chave[i] ==0:\n",
        "            drop_list.append(0)\n",
        "        else:\n",
        "            if chave[i] % 2 == 0:\n",
        "                drop_list.append(0.2)\n",
        "            else: \n",
        "\n",
        "                drop_list.append(0.1)\n",
        "\n",
        "    for i in range(7,13):\n",
        "        unit_list.append(chave[i])\n",
        "\n",
        "    desc = rede_desc(bl_list, unit_list, drop_list)\n",
        "    if verbose: print('\\t'+desc)\n",
        "    else: print('.',sep='',end='')\n",
        "    return bl_list, unit_list, drop_list, desc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfUDl8XIuX7e"
      },
      "source": [
        "def monta_modelo(bl_list, unit_list, drop_list):\n",
        "    '''\n",
        "    Modelo Keras\n",
        "    '''\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(1,shape_in)))\n",
        "\n",
        "    for e,i in enumerate(unit_list):\n",
        "        if i > 0:\n",
        "            if e < 2:           # LSTM\n",
        "                if bl_list[e]:\n",
        "                    model.add(tf.keras.layers.Bidirectional(LSTM (units = i, return_sequences=True )))    \n",
        "                else:\n",
        "                    model.add(tf.keras.layers.LSTM(units = i, return_sequences=True ))\n",
        "\n",
        "            else:               #MLP\n",
        "                model.add(tf.keras.layers.Dense(units = i, activation=tf.nn.relu) )\n",
        "            if e < 5:\n",
        "                                #Dropout\n",
        "                model.add(tf.keras.layers.Dropout(drop_list[e], seed = seed) )\n",
        "    model.add(tf.keras.layers.Dense(shape_out))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PzO_O9XMrhB"
      },
      "source": [
        "def func_aptidao(individual, verbose = False):\n",
        "    \"\"\"\n",
        "    Calcula a aptidão de cada individuo\n",
        "\n",
        "    :param individual:   Cromosomo de genes representando um individuo\n",
        "    :return:             A aptidão individual e MAPE\n",
        "    \"\"\"\n",
        "    reset_seed(seed)    #Para Garantir a repetibilidae do modelo\n",
        "\n",
        "    bl_list, unit_list, drop_list, desc = decode_gen(individual)\n",
        "    model = monta_modelo(bl_list, unit_list, drop_list)\n",
        "        \n",
        "    with tf.device(':CPU:0'):\n",
        "\n",
        "        model.compile(optimizer = 'adam',loss='mse', metrics=['accuracy','mape'])\n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor = 'loss',\n",
        "                                            patience = 10)\n",
        "        model.fit(  x=X_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=None,\n",
        "                    epochs=10000,\n",
        "                    verbose=False,\n",
        "                    callbacks=[early_stop],\n",
        "                    validation_split=0.0,\n",
        "                    #validation_data=(X_test,y_test),\n",
        "                    shuffle=False,\n",
        "                    class_weight=None,\n",
        "                    sample_weight=None,\n",
        "                    initial_epoch=0,\n",
        "                    steps_per_epoch=19,\n",
        "                    validation_steps=1,\n",
        "                    validation_batch_size=None,\n",
        "                    validation_freq=1,\n",
        "                    max_queue_size=10,\n",
        "                    workers=1,\n",
        "                    use_multiprocessing=False)\n",
        "        y_pred_norm = model.predict(X_test)\n",
        "\n",
        "        if shape_out ==1:\n",
        "            y_pred = output_scaler.inverse_transform(y_pred_norm.ravel().reshape(-1, 1))\n",
        "        else:\n",
        "            y_pred = output_scaler.inverse_transform(y_pred_norm.reshape(12,shape_out))\n",
        "\n",
        "        mape = mean_absolute_percentage_error(y_real,y_pred)\n",
        "        apti = 1-mape\n",
        "\n",
        "    if verbose: print('\\t\\t','mape','|',mape, '||', 'aptidão','|',apti)\n",
        "    else: print('.',sep='',end='')\n",
        "    set_seed_rand()\n",
        "    yp = y_pred.reshape(12,shape_out)\n",
        "    return mape, apti, yp"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDgG-A-dB3Sb"
      },
      "source": [
        "#### Seleção de Progenitores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA_1TWLWU6Jv"
      },
      "source": [
        "def selecao_de_progenitores(individuos, probabilidades, pares, verbose = False):\n",
        "    \"\"\"\n",
        "    Seleciona os pais de acordo com a estratégia \"roulette_wheel\" que seleciona \n",
        "    individuos aleatoriamente utilizando a maior aptidão como maior \n",
        "    probabilidade \n",
        "    \n",
        "    param individuos:       Numero de individuos\n",
        "    param probabilidades:  distribuíção de probabilidade\n",
        "    return:                pares escolhidos aleatoriamente\n",
        "    \"\"\"\n",
        "    from math import ceil\n",
        "    n = len(individuos)\n",
        "    pares = int(pares)\n",
        "    if pares*2 > n:\n",
        "        pares = n/2\n",
        "    \n",
        "    p1, p2 = None, None\n",
        "    pn = np.random.choice(range(n),2*pares, replace = False,p=probabilidades)\n",
        "    pr = np.random.choice(pn,len(pn),replace=False)\n",
        "    pp = np.array(pr).reshape(ceil(len(pn)/2),2)\n",
        "\n",
        "    if verbose: print('\\t\\t',pp)   \n",
        "    else: print('.',sep='',end='')\n",
        "    return pp"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSUcfijECBWJ"
      },
      "source": [
        "#### Cruzamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD7Q9oZysfzC"
      },
      "source": [
        "def cruzamento(casal, populacao, ng, verbose = False ):\n",
        "    '''\n",
        "    param casal:     index tupla (p1,p2) do casal que ira cruzar\n",
        "    param populacao: recebe a popopulação atual \n",
        "\n",
        "    return:          2 filhos com os cruzamentos aleatórios dos genes \n",
        "    '''\n",
        "    p1 = casal[0]   #progenitor 1\n",
        "    p2 = casal[1]   #progenitor 2\n",
        "    f1 = []         #filho 1\n",
        "    f2 = []         #filho 2\n",
        "    ng = populacao[p1].shape[0]\n",
        "\n",
        "    if verbose:\n",
        "        print('\\t\\tpar --', casal,'------')\n",
        "        print('\\t\\tp:',p1,populacao[p1]) #p1\n",
        "        print('\\t\\tp:',p2,populacao[p2]) #p2\n",
        "    else: print('.',sep='',end='')\n",
        "\n",
        "    s1=np.ones(ng)\n",
        "    while(s1.sum()==ng or s1.sum()==0):   # garantia de que havera ao menos \n",
        "        s1=np.random.choice([0,1],ng)    # 1 cruzamento\n",
        "    if verbose: print('\\t\\txxx ', s1)\n",
        "    else: print('.',sep='',end='')\n",
        "    for i, b in enumerate(s1):\n",
        "        #print(i,b)\n",
        "        if b:\n",
        "            #print(x[7][i])\n",
        "            f1.append(populacao[p1][i])\n",
        "            f2.append(populacao[p2][i])\n",
        "        else:\n",
        "            #print(x[9][i])\n",
        "            f1.append(populacao[p2][i])\n",
        "            f2.append(populacao[p1][i])\n",
        "    if verbose:\n",
        "        print('\\t\\tf1  ',f1)\n",
        "        print('\\t\\tf2  ',f2)\n",
        "    else: print('.',sep='',end='')\n",
        "    return np.array(f1),np.array(f2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHnPzBSFCQPw"
      },
      "source": [
        "#### Mutação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMO4_OMZ-NrU"
      },
      "source": [
        "#mutacao\n",
        "def mutacao(original, proba_mut, ng, verbose= False):\n",
        "    '''\n",
        "    apartir de um individuo original será gerado 1 individuo mutante\n",
        "    \n",
        "    param original:     cromossomo do individuo original\n",
        "    param proba_mut:    probabilidade de mutação \n",
        "    return:             mutante\n",
        "    '''\n",
        "    mutante = [] \n",
        "    if verbose: print('\\t\\tori ', original)\n",
        "    else: print('.',sep='',end='')\n",
        "    \n",
        "    gm = np.random.choice(64,ng)    #Sequencia mutante Aleatória\n",
        "\n",
        "    s1=np.ones(ng)\n",
        "    while(s1.sum()==0):   # garantia de que havera ao menos \n",
        "        s1=np.random.choice([0,1],ng,p=[1-proba_mut,proba_mut])    # 1 mutação\n",
        "    if verbose: print('\\t\\txxx ', s1)\n",
        "    else: print('.',sep='',end='')\n",
        "    for i, b in enumerate(s1):\n",
        "        #print(i,b)\n",
        "        if b:\n",
        "            #print(x[7][i])\n",
        "            mutante.append(gm[i])\n",
        "            \n",
        "        else:\n",
        "            mutante.append(original[i])\n",
        "    if verbose: print('\\t\\tmut ',mutante)\n",
        "    else: print('.',sep='',end='')\n",
        "    return  np.array(mutante)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjwhcp5u3hrT"
      },
      "source": [
        "###Busca e Salvamento "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbGk4XdVpTcE"
      },
      "source": [
        "def busca_item_lista(_item, _lista):\n",
        "    '''\n",
        "    Percorre a lista de arrays e retorna a posição se encontrar ou false se \n",
        "    não enontrar \n",
        "    \n",
        "    '''\n",
        "    for index, it in enumerate(_lista): \n",
        "\n",
        "        #print(index,it,_item, all(it==_item))\n",
        "        if (all(it==_item)):\n",
        "            return True, index\n",
        "    return False, False"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxCVkf9OcwhI"
      },
      "source": [
        "def salva_arca(_ep,idtest):\n",
        "    now = datetime.now().strftime('_%y_%m_%d-%H_%M_')\n",
        "    url = patha + 'arca' +str(idtest)+ now + str(_ep) + '.csv'\n",
        "    #arca = pd.DataFrame([arca_gen,arca_mape,arca_apt]).T\n",
        "    arca = pd.DataFrame(dic_arca).T.iloc[:,-3:]   \n",
        "    arca.columns = ['gen','mape','apt']\n",
        "    arca.apt = 1-arca.mape  #correção de aptidão relativa para geral\n",
        "    arca.to_csv(url,index=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehhs0DBKlhnc"
      },
      "source": [
        "def recupera_arca():\n",
        "    '''\n",
        "    Recupera dados de testes passados\n",
        "    \n",
        "    return: arca_gen, arca_mape, arca_apt, dic_arca, dic_arca_i\n",
        "    '''\n",
        "    url = patha + 'arca.csv'\n",
        "    arca_gen_str = pd.read_csv(url).gen.to_list()\n",
        "    arca_mape    = pd.read_csv(url).mape.to_list()\n",
        "    arca_apt     = pd.read_csv(url).apt.to_list()\n",
        "\n",
        "    arca_gen = []\n",
        "    for e, arc_g in enumerate(arca_gen_str):\n",
        "        arca_gen.append(gene_str2numpy(arc_g))\n",
        "    print(len(arca_gen))\n",
        "    dic_arca = {} # Cria dicionário vazio. # set() = conjunto vazio\n",
        "    dic_arca_i = {} \n",
        "    for e, i in enumerate(arca_gen):\n",
        "        dic_arca[tuple(i)] = [e,i,arca_mape[e],arca_apt[e]]\n",
        "        dic_arca_i[e] = i    \n",
        "\n",
        "    return arca_gen, arca_mape, arca_apt, dic_arca, dic_arca_i"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjV5xEBi1EOe"
      },
      "source": [
        "#arca_gen, arca_mape, arca_apt, dic_arca, dic_arca_i = recupera_arca()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfin4AGj3nRu"
      },
      "source": [
        "#len(arca_gen) == len(arca_mape)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EPrRTzW_j2Q"
      },
      "source": [
        "def gene_str2numpy(_str): \n",
        "    '''\n",
        "\n",
        "    return: np.array com a sequencialida \n",
        "    '''\n",
        "    indice = []\n",
        "    arn = [] \n",
        "    ultimo = 9999\n",
        "    for i, c in enumerate(_str):\n",
        "        if ord(c) in (91,32,93):\n",
        "            if i != ultimo + 1:\n",
        "                indice.append(i)\n",
        "            # print(i,c,ord(c),)\n",
        "                ultimo = i\n",
        "\n",
        "    for i in range(len(indice)-1):\n",
        "        n_str =_str[indice[i]+1:indice[i+1]]\n",
        "        arn.append(int(n_str.strip()))\n",
        "    return np.array(arn)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no5Wv068sNfI"
      },
      "source": [
        "def salva_resultado(_ep,_res,_mut,_tempo,_pop,_pop_r,_pop_c,idtest):\n",
        "    now = datetime.now().strftime('_%y_%m_%d-%H_%M_')\n",
        "    url = path + 'resultado' +str(idtest)+ now + str(_ep) + '.csv'\n",
        "    result = pd.DataFrame([_res,_mut,_tempo,_pop,_pop_r,_pop_c]).T\n",
        "    result.columns = ['Mape','Mutacao','Tempo','Populacao','Pop_Recuperada','Pop_Calculada']\n",
        "    result.to_csv(url,index = False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Px89HqhoVpS"
      },
      "source": [
        "def atualiza_arca(_bol):\n",
        "    if _bol:\n",
        "        os.chdir(patha)\n",
        "        extension = 'csv'\n",
        "        all_filenames = [i for i in glob.glob('arca*.{}'.format(extension))]\n",
        "        if len(all_filenames):\n",
        "            now = datetime.now().strftime('%y_%m_%d-%H_%M')\n",
        "            url = pathb + 'arca_bkp_' + now + '.csv'\n",
        "            if os.path.exists(patha+'arca.csv'):\n",
        "                pd.read_csv(patha+'arca.csv').to_csv(url)\n",
        "            #combine all files in the list\n",
        "            combined = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "            filtred = combined[['gen','mape','apt']].sort_values('mape').drop_duplicates()\n",
        "            #export to csv\n",
        "            filtred.to_csv(\"arca.csv\", index=False, encoding='utf-8-sig')\n",
        "            # move arquivos para o bkp\n",
        "            for f in all_filenames:\n",
        "                if f !='arca.csv':\n",
        "                    shutil.move(patha+f,pathb+f)\n",
        "                    print(f)\n",
        "\n",
        "#https://www.freecodecamp.org/news/how-to-combine-multiple-csv-files-with-8-lines-of-code-265183e0854/\n",
        "#https://datatofish.com/move-file-python/"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023PYOuNJLyU"
      },
      "source": [
        "if 0:\n",
        "    dfa = pd.read_csv(patha + 'arca.csv')\n",
        "    dfa['len'] = dfa['gen'].apply(lambda x: len(x))\n",
        "    #dfa['len'].count_values()\n",
        "    dfb=dfa[dfa['len'] == 40]\n",
        "    dfb.drop(['len'], axis =1 ,inplace = True)\n",
        "    dfb.sort_values('mape').to_csv(patha + 'arca.csv', index = False)\n",
        "    pd.read_csv(patha + 'arca.csv')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRhc0X3Z0Ex"
      },
      "source": [
        "def df_arca_hist(df):\n",
        "    '''\n",
        "    Gera dados únicos para comparativo em histograma, considerando que:\n",
        "    (3, 2, 0, 1) = (3, 2, 1)\n",
        "    uma vez que na lógica implementada para arquiterura MLP a camada com 0 \n",
        "    neurônios é suprimida.\n",
        "    '''\n",
        "    arca_hist = df[['gen','mape']]\n",
        "    arca_hist['gen'] = arca_hist.gen.apply(lambda g: gene_str2numpy(g))\n",
        "    arca_hist['dim'] = arca_hist.gen.apply(lambda x: np.shape(x)[0])\n",
        "    arca_hist['gen'] = arca_hist.gen.apply(lambda x: str(x[np.where(x)]))\n",
        "    arca_hist.drop_duplicates(inplace=True)\n",
        "    \n",
        "    return arca_hist[arca_hist.dim != 0]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2z18ZjG3v_I"
      },
      "source": [
        "###Relatórios e Medidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIvhFuiq1qz7"
      },
      "source": [
        "def time_diff(T1, verbose = False):\n",
        "    T2 = datetime.now()\n",
        "    format = '%H:%M'\n",
        "    #tdiff = datetime.strptime(T1, format) - datetime.strptime(T2, format)\n",
        "    tdiff = T2 - T1\n",
        "    #if tdiff. < 0:\n",
        "    #    tdiff = timedelta(days = 0,\n",
        "    #                seconds = tdiff.seconds, microseconds = tdiff.microseconds)\n",
        "    tdiff.total_seconds\n",
        "    if verbose: print( '....tempo transcorrido ', tdiff)\n",
        "    return tdiff.total_seconds()/60\n",
        "#"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3omgYVHnH-"
      },
      "source": [
        "def formatador_de_milhares(valor, p):\n",
        "        valor = f\"{valor:,.0f}\"\n",
        "        mapa_de_traducao = str.maketrans(',.', '.,')\n",
        "        return valor.translate(mapa_de_traducao)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5xM4D3a43T2"
      },
      "source": [
        "#### Relatório Parcial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH7R3k2z67Ez"
      },
      "source": [
        "def relatorio_parcial(ep, \n",
        "                      count_parada,\n",
        "                      arca_gen,\n",
        "                      ar_mape_gen, \n",
        "                      ar_mape_min,\n",
        "                      ar_mape_ind,\n",
        "                      \n",
        "                      ge_mape_gen,\n",
        "                      ge_mape_min,\n",
        "                      ge_mape_ind,\n",
        "                      \n",
        "                      list_tdiff, \n",
        "                      list_t_pop,\n",
        "                      list_t_pop_c, \n",
        "                      list_t_pop_r, \n",
        "                      list_mutacao,\n",
        "                      max_comb,\n",
        "                      res,\n",
        "                      teste_mape\n",
        "                      ):\n",
        "    print('__________________RELATÓRIO PARCIAL________________________________'\n",
        "    ,'\\n\\t\\t Geração                    =', ep                  \n",
        "    ,'\\n\\t\\t Parado                     =', count_parada        \n",
        "    ,'\\n\\t\\t Códigos na arca            =', len(arca_gen)\n",
        "    ,'\\n\\t\\t % da população avaliada    =', f'{(len(arca_gen)/max_comb)*100:.5f} %'\n",
        "    ,'\\n\\t\\t Tempo médio por geração    =', f'{np.mean(list_tdiff):.5f} %'\n",
        "    ,'\\n\\t\\t Tempo médio por ind_c      =', f'{sum(list_tdiff)/sum(list_t_pop):.2f} min'\n",
        "    ,'\\n-->Nesta Geração:_____________________________________________________'\n",
        "    ,'\\n\\t\\t Novos indivíduos Testados  =', sum(list_t_pop_c)                \n",
        "    ,'|'                                  , f'{(sum(list_t_pop_c)/max_comb)*100:.5f} %'\n",
        "    ,'\\n\\t\\t Clones indivíduos Testados =', sum(list_t_pop_r)\n",
        "    ,'\\n\\t\\t Total indivíduos Testados  =', sum(list_t_pop)\n",
        "    ,'|'                                  , f'{(sum(list_t_pop)/max_comb)*100.:.5f} %'\n",
        "    #,'\\n\\t\\t Tempo por indivíduos novo  =', f'{sum(list_tdiff)/sum(list_t_pop_c):.2f} min'\n",
        "    #,'\\n\\t\\t %(indivíduos novo/Testados)=', f'{(sum(list_t_pop_c)/max_comb)*100:.5} %'\n",
        "    )\n",
        "\n",
        "    _,_,_, desc1 = decode_gen(ge_mape_gen)\n",
        "    _,_,_, desc2 = decode_gen(ar_mape_gen)\n",
        "\n",
        "    print('--------Melhor desta Geração ----------',\n",
        "          '\\n\\t\\t MAPE      = ', round(ge_mape_min,6),\n",
        "          '\\n\\t\\t id_arca   = ', ge_mape_ind         ,\n",
        "          '\\n\\t\\t gen       = ', ge_mape_gen         , \n",
        "          '\\n\\t'               , desc1         \n",
        "          )\n",
        "\n",
        "    print('------------Melhor testado ------------',\n",
        "          '\\n\\t\\t MAPE      = ', round(ar_mape_min,6),\n",
        "          '\\n\\t\\t id_arca   = ', ar_mape_ind         ,\n",
        "          '\\n\\t\\t gen       = ', ar_mape_gen         ,\n",
        "          '\\n\\t'               , desc2               ,\n",
        "          )\n",
        "    fig, axs = plt.subplots(3,2, figsize=(12,15))\n",
        "       \n",
        "    sns.lineplot(ax=axs[0,0],x=range(len(res)),y=res)\n",
        "    axs[0,0].set_title('MAPE mínimo por Geração')\n",
        "    axs[0,0].set_ylabel('MAPE')\n",
        "    #axs[0,0].set_xlabel('Geração')\n",
        "    \n",
        "    sns.lineplot(ax=axs[1,0],x=range(len(list_mutacao)),y=list_mutacao)\n",
        "    axs[1,0].set_title('Evolução do Fator de mutação')\n",
        "    axs[1,0].set_ylabel('Fator de mutação')\n",
        "    #axs[1,0].set_xlabel('Geração')\n",
        "    \n",
        "    sns.lineplot(ax=axs[0,1],x=range(len(list_t_pop)),y=list_t_pop, label = 'total')\n",
        "    sns.lineplot(ax=axs[0,1],x=range(len(list_t_pop_c)),y=list_t_pop_c, label = 'calculada')\n",
        "    sns.lineplot(ax=axs[0,1],x=range(len(list_t_pop_r)),y=list_t_pop_r, label = 'recuperada')\n",
        "    axs[0,1].set_title('Evolução tamanho da população')\n",
        "    axs[0,1].set_ylabel('Indivíduos')\n",
        "    #axs[0,1].set_xlabel('Geração')\n",
        "        \n",
        "    sns.lineplot(ax=axs[1,1],x=range(len(list_tdiff)),y=list_tdiff)\n",
        "    sns.lineplot(ax=axs[1,1],x=range(len(list_tdiff)),y=np.mean(list_tdiff))\n",
        "    axs[1,1].set_title('Perfil de tempo por iteração')\n",
        "    axs[1,1].set_ylabel('tempo [min]')\n",
        "    #axs[1,1].set_xlabel('Geração')\n",
        "        \n",
        "    sns.histplot(ax=axs[2,0],data=teste_mape, kde=True)\n",
        "    axs[2,0].set_title('Distribuíção de erro por genoma teste')\n",
        "\n",
        "    list_t_pop_a = []\n",
        "    list_t_pop_ca = []\n",
        "    list_t_pop_ra = []\n",
        "    for e,i in enumerate(list_t_pop_c):\n",
        "        list_t_pop_a.append(sum(list_t_pop[:e+1]))\n",
        "        list_t_pop_ca.append(sum(list_t_pop_c[:e+1]))\n",
        "        list_t_pop_ra.append(sum(list_t_pop_r[:e+1]))\n",
        "    sns.lineplot(ax=axs[2,1],x=range(len(list_t_pop_a)),\n",
        "                 y=list_t_pop_a,label = 'total')\n",
        "    sns.lineplot(ax=axs[2,1],x=range(len(list_t_pop_ca)),\n",
        "                 y=list_t_pop_ca, label = 'calculada')\n",
        "    sns.lineplot(ax=axs[2,1],x=range(len(list_t_pop_ra)),\n",
        "                 y=list_t_pop_ra,label = 'recuperada')\n",
        "    #sns.ecfplot(ax=axs[2,1],list_t_pop_t, label = 'indivíduos avaliados')\n",
        "    axs[2,1].set_title('População acumulada')\n",
        "    axs[2,1].set_ylabel('Indivíduos')\n",
        "        \n",
        "    #arca_hist = df_arca_hist(pd.read_csv(urla))\n",
        "    #sns.histplot(ax=axs[2,1],data=arca_hist, kde=True)\n",
        "    #axs[2,1].set_title('Distribuíção de erro por genoma hist.')\n",
        " \n",
        "    plt.suptitle('Resultados dos testes Geração = '+str(ep) , y=.93, fontsize=17)\n",
        "    plt.show();"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWCcJJOm477I"
      },
      "source": [
        "#### Perfil de Consumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVzcSN8V_To_"
      },
      "source": [
        "def plt_consumo12(y_true,y_pred):\n",
        "    plt.figure(figsize=(10,8))\n",
        "    ax1 = sns.lineplot(x=range(1,13),y=y_true, label='Real')\n",
        "    ax2 = sns.lineplot(x=range(1,13),y=y_pred.ravel(), label='LSTM')\n",
        "    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(formatador_de_milhares))\n",
        "    plt.legend()\n",
        "    plt.grid('-')\n",
        "    plt.ylabel('Consumo [MWh]')\n",
        "    #ax2.set_xticks(ax2.get_xticks()[::3])\n",
        "    #plt.xticks(rotation = 90, fontsize=10)\n",
        "    plt.show();"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi_8A1Dan5q0"
      },
      "source": [
        "def plt_barras(x,y,*titulo):\n",
        "    plt.figure(figsize=(12,8))\n",
        "    sns.set_style('darkgrid')\n",
        "    g = sns.barplot(x=x, y=y, palette='rocket')\n",
        "    plt.title('MAPE por SetorN1', fontsize = 17)\n",
        "    \n",
        "    for i in range(len(x)):\n",
        "        g.text(i,y[i]+0.001, round(y[i],3), color='black', ha=\"center\", fontsize=15)\n",
        "    plt.xticks(rotation = 90, fontsize=15)\n",
        "    plt.ylabel('MAPE')\n",
        "    #plt.xlabel('SetorN1')\n",
        "    plt.show()\n",
        "    ;"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyLNzwwF6R6d"
      },
      "source": [
        "def plt_perfis_de_consumo(yp):\n",
        "    list_mape = []\n",
        "\n",
        "    fig, axs = plt.subplots(3,3, figsize=(12,15))\n",
        "    for e, i in enumerate(y.columns):\n",
        "        if e < 3:\n",
        "            s = 0\n",
        "        elif e < 6: \n",
        "            s = 1\n",
        "        else:\n",
        "            s = 2\n",
        "\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=yp[:,e]/1000, label = 'pred')\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=y.iloc[60:,e]/1000, label = 'real')\n",
        "        axs[s,e-s*3].set_title(i)\n",
        "        axs[s,e-s*3].set_xlabel('')\n",
        "        axs[s,e-s*3].set_ylabel('')\n",
        "        #axs[s,e-s*3].set_ylim(0,3_000_000)\n",
        "        axs[s,e-s*3].set_ylim(0)\n",
        "        axs[s,e-s*3].set_xticks(range(0,13,2))\n",
        "        axs[s,e-s*3].set_xlim(1, 12)\n",
        "        axs[s,e-s*3].yaxis.set_major_formatter(ticker.FuncFormatter(formatador_de_milhares))\n",
        "        mape = mean_absolute_percentage_error(y.iloc[60:,e],yp[:,e])\n",
        "        list_mape.append(mape)\n",
        "    list_mape.append(np.array(list_mape).mean())\n",
        "\n",
        "    plt.suptitle('Consumo [kW] por SetorN1' , y=.93, fontsize=17)\n",
        "    plt.show()\n",
        "    ;\n",
        "    if 0:\n",
        "        y_bars = [*y.columns,'Média']\n",
        "        plt.figure(figsize=(12,8))\n",
        "        sns.set_style('darkgrid')\n",
        "        g = sns.barplot(x=y_bars, y=list_mape, palette='rocket')\n",
        "        plt.title('MAPE por SetorN1', fontsize = 17)\n",
        "        \n",
        "        for i in range(len(y_bars)):\n",
        "            g.text(i,list_mape[i]+0.001, round(list_mape[i],3), color='black', ha=\"center\", fontsize=15)\n",
        "        plt.xticks(rotation = 90, fontsize=15)\n",
        "        plt.ylabel('MAPE')\n",
        "        #plt.xlabel('SetorN1')\n",
        "        plt.show()\n",
        "        ;"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7LfcOT4RFXZ"
      },
      "source": [
        "def plt_perfis_de_consumo2(yp):\n",
        "    yp = y_pred_list.T\n",
        "    list_mape = []\n",
        "\n",
        "    fig, axs = plt.subplots(2,3, figsize=(12,15))\n",
        "    for e, i in enumerate(y.columns):\n",
        "        if e < 3:\n",
        "            s = 0\n",
        "        elif e < 6: \n",
        "            s = 1\n",
        "        else:\n",
        "            s = 2\n",
        "        print(e, i)\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=yp[-12:,e]/1000, label = 'pred')\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=y.iloc[-12:,e]/1000, label = 'real')\n",
        "        axs[s,e-s*3].set_title(i)\n",
        "        axs[s,e-s*3].set_xlabel('')\n",
        "        axs[s,e-s*3].set_ylabel('')\n",
        "        #axs[s,e-s*3].set_ylim(0,3_000_000)\n",
        "        axs[s,e-s*3].set_ylim(0)\n",
        "        axs[s,e-s*3].set_xticks(range(0,13,2))\n",
        "        axs[s,e-s*3].set_xlim(1, 12)\n",
        "        axs[s,e-s*3].yaxis.set_major_formatter(ticker.FuncFormatter(formatador_de_milhares))\n",
        "        mape = mean_absolute_percentage_error(y.iloc[-12:,e],yp[:,e])\n",
        "        list_mape.append(mape)\n",
        "    list_mape.append(np.array(list_mape).mean())\n",
        "\n",
        "    plt.suptitle('Consumo [kW] por SetorN1' , y=.93, fontsize=17)\n",
        "    y_bars = [*y.columns,'Média']\n",
        "    g = sns.barplot(ax=axs[1,2], x=y_bars, y=list_mape, palette='rocket')\n",
        "    for i in range(len(y_bars)):\n",
        "        g.text(i,list_mape[i]+0.001, round(list_mape[i],3), color='black', ha=\"center\", fontsize=10)\n",
        "    plt.xticks(rotation = 90, fontsize=10)\n",
        "    plt.title('MAPE por SetorN1', fontsize = 10)\n",
        "\n",
        "    plt.show()\n",
        "    ;"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hrzK_5UfF8i"
      },
      "source": [
        "###Algoritmo Genético"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5WnM-44P5wr"
      },
      "source": [
        "def algoritmo_genetico(\n",
        "                ini_pop         = True    ,    \n",
        "                pop_selecao     = 0       ,   \n",
        "                recup_memo      = False   ,    \n",
        "                epocas          = 100     ,    \n",
        "                pop_tamanho     = 64      ,    \n",
        "                n_genes         = 13      ,    \n",
        "                limites_genes   = (0,64)  ,    \n",
        "                indice_mut      = 0.2     ,    \n",
        "                #casais         = int((pop_tamanho+pop_selecao)/4)  ,\n",
        "                max_parado      = 200     ,    \n",
        "                alvo            = 0.001   ,\n",
        "                bool_salva_arca = False   ,\n",
        "                verbose         = False\n",
        "    ):\n",
        "    '''\n",
        "    Parâmetros de entrada: \n",
        "    ini_pop        # Inicializa população aleatória\n",
        "    pop_selecao    # N melhore hist Selecionados para geração 0 \n",
        "    recup_memo     # True recupera memória de iterações passadas\n",
        "    epocas         # total de gerações/Epocas\n",
        "    pop_tamanho    # tamanho da inicial população\n",
        "    n_genes        # Número de Genes\n",
        "    limites_genes  # Limite de valores para cada Gene\n",
        "    indice_mut     # Probaabilidade de Mutação inicial \n",
        "    #casais        # Número de casais Progenitores\n",
        "    max_parado     # Limite de epocas parado no mesmo erro\n",
        "    alvo           # Erro Alvo\n",
        "    bol_salva_arca # Exportar resultados\n",
        "    verbose        # Saída de fluxo\n",
        "\n",
        "    Saídas \n",
        "    Código Genético do melhor modelo\n",
        "    Valor de Erro (MAPE) do melhor modelo\n",
        "    '''\n",
        "    #--------------------------------------------------------------------------\n",
        "    ## Variáveis de Controle\n",
        "    casais          = int((pop_tamanho+pop_selecao)/4)\n",
        "    arca_gen        = []           # Memória genetica\n",
        "    arca_apt        = []           # Memória de aptidão \n",
        "    arca_mape       = []           # Memória de mape \n",
        "    teste_mape      = []\n",
        "    count_parada    = 0\n",
        "    count_pop_r     = 0\n",
        "    count_pop_c     = 0\n",
        "    res             = []\n",
        "    elite           = []\n",
        "    list_mutacao    = []\n",
        "    list_tdiff      = []\n",
        "    list_t_pop      = []\n",
        "    list_t_pop_r    = []\n",
        "    list_t_pop_c    = []\n",
        "    novos_individuos= []\n",
        "    pre_selecionado = []\n",
        "    selecionado     = []\n",
        "    pop             = []\n",
        "    ep              = 0\n",
        "\n",
        "    min_anterior  = 1\n",
        "    test_comb     = epocas*pop_tamanho\n",
        "    max_comb      = ((limites_genes[1]-limites_genes[0])+1)**n_genes\n",
        "\n",
        "    if verbose:\n",
        "\n",
        "        print('->Algoritmo genético de otimização -----------------------------------')\n",
        "        print(  '\\t Nova Populaçao                         = '  , ini_pop       ,\n",
        "            '\\n\\t Recupera memória de iterações passadas = '  , recup_memo    ,\n",
        "            '\\n\\t Gerações máximas                       = '  , epocas        ,\n",
        "            '\\n\\t Mais aptos selecionados em memória     = '  , pop_selecao   ,\n",
        "            '\\n\\t Tamanho da população                   = '  , pop_tamanho   ,\n",
        "            '\\n\\t Número de Genes                        = '  , n_genes       ,\n",
        "            '\\n\\t Limite de valores para cada Gene       = '  , limites_genes ,\n",
        "            '\\n\\t Probabilidade de Mutação inicial       = '  , indice_mut    ,\n",
        "            '\\n\\t Casais por época                       = '  , casais        ,\n",
        "            '\\n\\t Limite de épocas parado no mesmo erro  = '  , max_parado    ,\n",
        "            '\\n\\t Erro Alvo                              = '  , alvo          ,\n",
        "            '\\n\\t Total de combinações no teste          = '  , test_comb/20  ,\n",
        "            '\\n\\t Tempo de execução estimado em horas    = '  , test_comb/20  ,\n",
        "            '\\n\\t Total de combinações possíveis         = '  , max_comb      ,\n",
        "            '\\n\\t Tempo máximo max comb. em anos         = '  , max_comb/175200\n",
        "            )\n",
        "    else: print('.',sep='',end='')\n",
        "\n",
        "    if os.path.isfile(patha+'arca.csv') and recup_memo:\n",
        "        arca_gen, arca_mape, arca_apt, dic_arca, dic_arca_i= recupera_arca()\n",
        "\n",
        "        if verbose:\n",
        "            print('--------------------------------------------------------------------'\n",
        "            ,'\\n\\t\\t\\t', len(arca_gen),'codigos recuperados'                \n",
        "            ,'\\n\\t\\t\\t', f'{(len(arca_gen)/max_comb)*100:.5f} % da população avaliada' )\n",
        "        else: print('.',sep='',end='')\n",
        "    else: \n",
        "        dic_arca = {}\n",
        "        dic_arca_i = {}\n",
        "    if ini_pop:\n",
        "        if verbose:\n",
        "            print('-->Inicializa População............................................')\n",
        "        else: print('.',sep='',end='')\n",
        "        pop = inicializa_populacao(pop_tamanho,n_genes,limites_genes)\n",
        "        if verbose: print('População Inicial:',pop)\n",
        "        else: print('.',sep='',end='')\n",
        "\n",
        "    if pop_selecao >0:\n",
        "        for e, i in enumerate(arca_gen):\n",
        "            if len(i) ==n_genes:\n",
        "                pre_selecionado.append(i)\n",
        "        if verbose: print (len(pre_selecionado),'possiveis de seleção')    \n",
        "        else: print('.',sep='',end='')\n",
        "        for e, i in enumerate(pre_selecionado[0:pop_selecao]):\n",
        "            if verbose: print (e,i, len(i))\n",
        "            else: print('.',sep='',end='')\n",
        "            selecionado.append(i)\n",
        "        pop += selecionado\n",
        "    for ep in range(epocas):\n",
        "        T1 = datetime.now()\n",
        "        gera_mape = []\n",
        "        count_pop_r = 0\n",
        "        count_pop_c = 0\n",
        "        if verbose:\n",
        "            print('-->>epoca',ep,'----------------------------------------------------')\n",
        "        else: print('\\n--># ep.',ep,sep='',end='')\n",
        "        #print('Novos Individuos:',novos_individuos)\n",
        "        if ep > 0: \n",
        "            if verbose:\n",
        "                print('-->>>Seleção---------------------------------------------------')\n",
        "            else: print('.',sep='',end='')\n",
        "            for i in progenitores.ravel():\n",
        "                # Progenitores selecionados aleatóriamente  #####\n",
        "                novos_individuos.append(pop[i])\n",
        "                if verbose: print(\"Progenitores\", pop[i])\n",
        "                else: print('.',sep='',end='')\n",
        "            for el in range(2):\n",
        "                # Elite garantindo os 2 melhores da geração anterior\n",
        "                bol, pos = busca_item_lista(elite[el],novos_individuos)\n",
        "                if not bol:\n",
        "                    if verbose: print('\\t\\t VIP', elite[el])\n",
        "                    else: print('.',sep='',end='')\n",
        "                    novos_individuos.append(elite[el])\n",
        "            pop = novos_individuos\n",
        "            novos_individuos = []\n",
        "        list_t_pop.append(len(pop))\n",
        "        #print('Novos Individuos:',novos_individuos)\n",
        "        probabilidades = []  \n",
        "        if verbose: print('-->>>Aptidão-------------------------------------------------------')\n",
        "        else: print('.',sep='',end='')\n",
        "        for id, individuo in enumerate(pop):\n",
        "            if verbose: print(ep,'#', id, individuo)\n",
        "            else: print('.',sep='',end='')\n",
        "            #bag, ibag = busca_item_lista(individuo, arca_gen)\n",
        "            \n",
        "            if tuple(individuo) in dic_arca:\n",
        "                if verbose:\n",
        "                    print('\\t__Individuo Clone Recuperado da Arca #id:',                      \n",
        "                        dic_arca[tuple(individuo)][0])\n",
        "                else: print('.',sep='',end='')\n",
        "                a = dic_arca[tuple(individuo)][3]\n",
        "                m = dic_arca[tuple(individuo)][2]\n",
        "                \n",
        "                if verbose:\n",
        "                    print('\\t arca_apt recuperado:',a)\n",
        "                    print('\\t arca_mape recuperado:',m)\n",
        "                else: print('.',sep='',end='')\n",
        "                count_pop_r +=1\n",
        "            else:\n",
        "                m,a,yp = func_aptidao(individuo)\n",
        "                dic_arca[tuple(individuo)]=[len(dic_arca),individuo,m,a]\n",
        "                dic_arca_i[len(dic_arca_i)]=individuo\n",
        "                arca_gen.append(individuo)\n",
        "                arca_apt.append(a)\n",
        "                arca_mape.append(m)\n",
        "                count_pop_c +=1\n",
        "            #print(probabilidades)\n",
        "            if m>1:\n",
        "                probabilidades.append(0)\n",
        "            else: \n",
        "                probabilidades.append(1-m)\n",
        "            gera_mape.append(m)\n",
        "            #print('\\t\\t individuo mape',individuo,m)\n",
        "            #print('\\t\\t',gera_mape)\n",
        "        list_t_pop_c.append(count_pop_c)\n",
        "        list_t_pop_r.append(count_pop_r)\n",
        "        probabilidades =(np.array(probabilidades)/sum(probabilidades))\n",
        "        #print('\\t população avaliada:', pop)\n",
        "        if verbose:\n",
        "            print('\\t Probabilidades:', np.round(probabilidades,4))\n",
        "            print('-->>>Elite---------------------------------------------------------')\n",
        "        else: print('.',sep='',end='')\n",
        "        \n",
        "        prob_elite = np.sort(probabilidades).tolist()[-2:]\n",
        "        elite = [   pop[probabilidades.tolist().index(prob_elite[0])],\n",
        "                    pop[probabilidades.tolist().index(prob_elite[1])]]\n",
        "        \n",
        "        if verbose:\n",
        "            print('\\t\\t Elite :', elite)\n",
        "\n",
        "            print('-->>>Progenitores--------------------------------------------------')\n",
        "        else: print('.',sep='',end='')\n",
        "        progenitores = selecao_de_progenitores(pop, probabilidades, casais) \n",
        "        \n",
        "        if verbose:\n",
        "            print('-->>>Cruzamento----------------------------------------------------')\n",
        "        for p in progenitores:\n",
        "            f1, f2 = cruzamento(p,pop, n_genes)\n",
        "            novos_individuos.append(f1)\n",
        "            novos_individuos.append(f2)\n",
        "        if verbose:\n",
        "            print('Novos Individuos F1:',f1)\n",
        "            print('Novos Individuos F2:',f2)\n",
        "        else: print('.',sep='',end='')\n",
        "        #print('Novos Individuos:',novos_individuos)\n",
        "        if verbose:\n",
        "            print('-->>>Mutação-------------------------------------------------------')\n",
        "        # Replicas com Mutação dos filhos \n",
        "        mutantes = [] \n",
        "        for en, ori in enumerate(novos_individuos):\n",
        "            mu = mutacao(ori,indice_mut,n_genes)\n",
        "            mutantes.append(mu)\n",
        "        novos_individuos += mutantes\n",
        "        # Replicas com mutação da elite\n",
        "        mutantes2 = [] \n",
        "        if verbose:\n",
        "            print('Novos Individuos:',novos_individuos)\n",
        "        else: print('.',sep='',end='')\n",
        "\n",
        "        for en, ori in enumerate(elite):\n",
        "            mu = mutacao(ori,indice_mut,n_genes)\n",
        "            mutantes2.append(mu)\n",
        "        novos_individuos += mutantes2\n",
        "        if verbose: print('Novos Individuos:',novos_individuos)\n",
        "        else: print('.',sep='',end='')\n",
        "        ## Resultados Parciais ----------------------------------------------------\n",
        "        teste_mape += gera_mape \n",
        "        ge_mape_min = (min(gera_mape))              # Menor erro na geração\n",
        "        \n",
        "        if verbose: print('\\n#', ep, ge_mape_min)\n",
        "        else: print('_#', ep, '_min MAPE',ge_mape_min,sep='',end='')\n",
        "        res.append(ge_mape_min)     \n",
        "        ge_mape_ind = arca_mape.index(ge_mape_min)  \n",
        "        ge_mape_gen = arca_gen[ge_mape_ind]\n",
        "        \n",
        "\n",
        "        list_mutacao.append(indice_mut)             # Indice de proba Mutação\n",
        "        list_tdiff.append(time_diff(T1))            # Tempo de Processamento \n",
        "        \n",
        "        ar_mape_min = min(arca_mape)     # Menor erro histórico\n",
        "        ar_mape_ind = arca_mape.index(ar_mape_min)  \n",
        "        ar_mape_gen = arca_gen[ar_mape_ind]\n",
        "    \n",
        "        if verbose: relatorio_parcial()\n",
        "        else: print('.',sep='',end='')\n",
        "\n",
        "        #Salva resultados Parciais    \n",
        "        idtest = n_genes\n",
        "        salva_resultado(ep,res,list_mutacao,list_tdiff,list_t_pop,\n",
        "                        list_t_pop_r,list_t_pop_c,idtest)\n",
        "        \n",
        "        if bool_salva_arca: salva_arca(ep,idtest)\n",
        "\n",
        "        # Critérios de parada\n",
        "        if ge_mape_min < alvo:\n",
        "            print('para por atingimento do alvo')\n",
        "            break\n",
        "        if verbose: print(f'\\t Min Erro Atual {ge_mape_min:.5f} x {min_anterior:.5f} Min Erro Anterior')\n",
        "        else: print('.',sep='',end='')\n",
        "        if round(ge_mape_min,5) == round(min_anterior,5):\n",
        "            count_parada +=1\n",
        "            if count_parada > 4:\n",
        "                if indice_mut < 0.81:\n",
        "                    indice_mut += 0.1\n",
        "                    if verbose: print('Indice Mutação: ', indice_mut)\n",
        "                    else: print('.',sep='',end='')\n",
        "                    count_parada = 0\n",
        "            if indice_mut > 0.81:\n",
        "                indice_mut = 0.8 \n",
        "\n",
        "            if count_parada > max_parado:\n",
        "                print('para por atingimento do limite de iterações parado')\n",
        "                break\n",
        "        else:\n",
        "            \n",
        "            min_anterior = min(ge_mape_min, min_anterior) #P/ Prox Laço \n",
        "            count_parada = 0\n",
        "        if verbose: print(f'\\t parado a {count_parada} epocas')\n",
        "        else: print('.',sep='',end='')\n",
        "\n",
        "        if ep+1 == epocas: \n",
        "            \n",
        "            relatorio_parcial(ep, \n",
        "                      count_parada,\n",
        "                      arca_gen,\n",
        "                      ar_mape_gen, \n",
        "                      ar_mape_min,\n",
        "                      ar_mape_ind,\n",
        "                      \n",
        "                      ge_mape_gen,\n",
        "                      ge_mape_min,\n",
        "                      ge_mape_ind,\n",
        "                      \n",
        "                      list_tdiff, \n",
        "                      list_t_pop,\n",
        "                      list_t_pop_c, \n",
        "                      list_t_pop_r, \n",
        "                      list_mutacao,\n",
        "                      max_comb,\n",
        "                      res,\n",
        "                      teste_mape\n",
        "                      )\n",
        "    print('Parada por maximo de interações: ', ep+1             )\n",
        "    print('Menor Mape  '                     , min(arca_mape)   )\n",
        "    print('Código  '                         , ar_mape_gen      )\n",
        "    print('Indice Mutação Final: '           , indice_mut       )\n",
        "\n",
        "    atualiza_arca(bool_salva_arca)\n",
        "\n",
        "    return  ar_mape_gen, min(arca_mape)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvNl16a2uRP5"
      },
      "source": [
        "# Main (Código Principal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wKLYqYkfiOB"
      },
      "source": [
        "atualiza_arca(False)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5rF9M7QnhfV",
        "outputId": "2b0edabf-a01e-450f-a2b8-b6831eb47974"
      },
      "source": [
        "%%time\n",
        "y_pred_list = []\n",
        "mape_list = []\n",
        "gen_list = []\n",
        "\n",
        "for e,i in enumerate(Ycolumns):\n",
        "    if 1:\n",
        "        shape_in, shape_out, X_train, y_train, X_test, y_test, y_real, input_scaler, output_scaler = TrainTestData(e)\n",
        "        print('#'*10, e, i, '#'*20)\n",
        "        gen, mape = algoritmo_genetico(epocas=32, pop_tamanho=16)\n",
        "        m_laco, _, y_laco = func_aptidao(gen)\n",
        "        y_pred_list.append(y_laco)\n",
        "        gen_list.append(gen)\n",
        "        mape_list.append(m_laco)\n",
        "mape_list.append(np.array(mape_list).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########## 0 Consumo ####################\n",
            "...\n",
            "--># ep.0....................WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f09741d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "....WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f0c40f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "........................................................................................._#0_min MAPE0.03817610117556778...\n",
            "--># ep.1.........................................................................................................................................................._#1_min MAPE0.035543019073925576...\n",
            "--># ep.2.................................................................................................................................................................._#2_min MAPE0.035543019073925576...\n",
            "--># ep.3..................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT2maHTx1rZv"
      },
      "source": [
        "# roda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsPYdowOxoNI"
      },
      "source": [
        "# Comparativo Validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2MJKAX8XVZH"
      },
      "source": [
        "#Relatório Manual agrupando os  resultados obtidos para cada SetorN1\n",
        "if 0:\n",
        "    list_mape = []\n",
        "    list_gen = []\n",
        "\n",
        "    ########## 0 Consumo \t\t####################\n",
        "    list_mape.append(0.035652)\n",
        "    list_gen.append(np.array([34, 58, 58, 14, 13,  7, 15,  1, 25, 26, 19, 37, 35])) \n",
        "    ########## 1 Comercial \t\t####################\n",
        "    list_mape.append(0.088187)\n",
        "    list_gen.append(np.array([29,  9, 13, 10, 58, 58, 13, 15, 59,  3, 50, 28,  3])) \n",
        "    ########## 2 Industrial \t####################\n",
        "    list_mape.append(0.049014)\n",
        "    list_gen.append(np.array([38, 19, 30,  7, 45, 41, 38, 58, 55,  6,  0, 25, 33])) \n",
        "    ########## 3 Residencial \t####################\n",
        "    list_mape.append(0.014144)\n",
        "    list_gen.append(np.array([20, 26, 49, 28, 31, 15,  0, 48, 58, 52, 23, 19, 11])) \n",
        "    ########## 4 Outros \t\t####################\n",
        "    list_mape.append(0.024953)\n",
        "    list_gen.append(np.array([57, 34,  1, 35, 59, 12, 57, 18, 48, 37, 39, 54, 60])) \n",
        "\n",
        "    list_mape.append(np.array(list_mape).mean())\n",
        "    barras = [*Ycolumns, 'Média']\n",
        "\n",
        "    plt_barras(barras,list_mape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C0-uh86OImQ"
      },
      "source": [
        "Ycolumns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLmBNdPC0AOw"
      },
      "source": [
        "y_pred_list = []\n",
        "mape_list = []\n",
        "\n",
        "for e,i in enumerate(Ycolumns):\n",
        "    if 1:\n",
        "        shape_in, shape_out, X_train, y_train, X_test, y_test, y_real, input_scaler, output_scaler = TrainTestData(e)\n",
        "        print('\\n'+('#'*10), e, i, ' '*(20-len(i))+'#'*20)\n",
        "        m_laco, _, y_laco = func_aptidao(gen_list[e])\n",
        "        y_pred_list.append(y_laco)\n",
        "        mape_list.append(m_laco)\n",
        "mape_list.append(np.array(mape_list).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ccC83f42Wcf"
      },
      "source": [
        "X,y,input_scaler,output_scaler,X_train,y_train,X_test,y_test,y_real,shape_in, shape_out = TrainTestData_old()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi0-JUj920ff"
      },
      "source": [
        "y_pred_list = np.array(y_pred_list).reshape(5,12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf2Asdcb2QUT"
      },
      "source": [
        "plt_perfis_de_consumo2(y_pred_list.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4HyPDh-ui8S"
      },
      "source": [
        "#Fim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpscZyePRT3s"
      },
      "source": [
        "#def plt_perfis_de_consumo2(yp = y_pred_list.T):\n",
        "if 1: \n",
        "    yp = y_pred_list.T\n",
        "    list_mape = []\n",
        "\n",
        "    fig, axs = plt.subplots(2,3, figsize=(12,15))\n",
        "    for e, i in enumerate(y.columns):\n",
        "        if e < 3:\n",
        "            s = 0\n",
        "        elif e < 6: \n",
        "            s = 1\n",
        "        else:\n",
        "            s = 2\n",
        "        print(e, i)\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=yp[-12:,e]/1000, label = 'pred')\n",
        "        sns.lineplot(ax=axs[s,e-s*3],x=range(1,13),y=y.iloc[-12:,e]/1000, label = 'real')\n",
        "        axs[s,e-s*3].set_title(i)\n",
        "        axs[s,e-s*3].set_xlabel('')\n",
        "        axs[s,e-s*3].set_ylabel('')\n",
        "        #axs[s,e-s*3].set_ylim(0,3_000_000)\n",
        "        axs[s,e-s*3].set_ylim(0)\n",
        "        axs[s,e-s*3].set_xticks(range(0,13,2))\n",
        "        axs[s,e-s*3].set_xlim(1, 12)\n",
        "        axs[s,e-s*3].yaxis.set_major_formatter(ticker.FuncFormatter(formatador_de_milhares))\n",
        "        mape = mean_absolute_percentage_error(y.iloc[-12:,e],yp[:,e])\n",
        "        list_mape.append(mape)\n",
        "    list_mape.append(np.array(list_mape).mean())\n",
        "\n",
        "    plt.suptitle('Consumo [kW] por SetorN1' , y=.93, fontsize=17)\n",
        "    y_bars = [*y.columns,'Média']\n",
        "    g = sns.barplot(ax=axs[1,2], x=y_bars, y=list_mape, palette='rocket')\n",
        "    for i in range(len(y_bars)):\n",
        "        g.text(i,list_mape[i]+0.001, round(list_mape[i],3), color='black', ha=\"center\", fontsize=10)\n",
        "    plt.xticks(rotation = 90, fontsize=10)\n",
        "    plt.title('MAPE por SetorN1', fontsize = 10)\n",
        "\n",
        "    plt.show()\n",
        "    ;"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}